{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ankitarora2/TechnoCulture/blob/main/AMIESignatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Serve the model using vLLM"
      ],
      "metadata": {
        "id": "IoWlaISn36OH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iRD5aN86v6ED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aeb0a64-19eb-429d-8fd6-0b760b17b2c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dspy-ai\n",
            "  Downloading dspy_ai-2.3.1-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting vllm\n",
            "  Downloading vllm-0.3.2-cp310-cp310-manylinux1_x86_64.whl (41.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff~=2.2.1 (from dspy-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: joblib~=1.3.2 in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (1.3.2)\n",
            "Collecting openai<2.0.0,>=0.28.1 (from dspy-ai)\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (1.5.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (2023.12.25)\n",
            "Collecting ujson (from dspy-ai)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (4.66.2)\n",
            "Collecting datasets<3.0.0,~=2.14.6 (from dspy-ai)\n",
            "  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dspy-ai) (2.31.0)\n",
            "Collecting optuna (from dspy-ai)\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from vllm)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n",
            "Collecting ray>=2.9 (from vllm)\n",
            "  Downloading ray-2.9.3-cp310-cp310-manylinux2014_x86_64.whl (64.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.1.99)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vllm) (1.25.2)\n",
            "Collecting torch==2.1.2 (from vllm)\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers>=4.38.0 (from vllm)\n",
            "  Downloading transformers-4.38.1-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xformers==0.0.23.post1 (from vllm)\n",
            "  Downloading xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from vllm)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard] (from vllm)\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.6.1)\n",
            "Collecting aioprometheus[starlette] (from vllm)\n",
            "  Downloading aioprometheus-23.12.0-py3-none-any.whl (31 kB)\n",
            "Collecting pynvml==11.5.0 (from vllm)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.1.0)\n",
            "Collecting cupy-cuda12x==12.1.0 (from vllm)\n",
            "  Downloading cupy_cuda12x-12.1.0-cp310-cp310-manylinux2014_x86_64.whl (83.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x==12.1.0->vllm) (0.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.2->vllm) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m94.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->vllm)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->vllm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets<3.0.0,~=2.14.6->dspy-ai)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (3.4.1)\n",
            "Collecting multiprocess (from datasets<3.0.0,~=2.14.6->dspy-ai)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,~=2.14.6->dspy-ai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=0.28.1->dspy-ai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=0.28.1->dspy-ai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=0.28.1->dspy-ai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=0.28.1->dspy-ai) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->vllm) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->vllm) (2.16.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (8.1.7)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.0.7)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dspy-ai) (2024.2.2)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.0->vllm) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.0->vllm) (0.4.2)\n",
            "Collecting orjson (from aioprometheus[starlette]->vllm)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting quantile-python>=1.1 (from aioprometheus[starlette]->vllm)\n",
            "  Downloading quantile-python-1.1.tar.gz (2.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting starlette>=0.14.2 (from aioprometheus[starlette]->vllm)\n",
            "  Downloading starlette-0.37.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna->dspy-ai)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna->dspy-ai)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->dspy-ai) (2.0.27)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy-ai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->dspy-ai) (2023.4)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]->vllm)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]->vllm)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]->vllm)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]->vllm)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]->vllm)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Mako (from alembic>=1.5.0->optuna->dspy-ai)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=0.28.1->dspy-ai) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,~=2.14.6->dspy-ai) (4.0.3)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=0.28.1->dspy-ai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->dspy-ai) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->dspy-ai) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.2->vllm) (2.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->vllm) (0.18.0)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets<3.0.0,~=2.14.6->dspy-ai)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.2->vllm) (1.3.0)\n",
            "Building wheels for collected packages: quantile-python\n",
            "  Building wheel for quantile-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for quantile-python: filename=quantile_python-1.1-py3-none-any.whl size=3444 sha256=9ef6394eaf22db25f66a011db219d246788e1d9c6b69508afe5492e781618824\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/f4/0a/0e7d01548a005f9f3fa23101f071d248da052f2a9bf2fe11c6\n",
            "Successfully built quantile-python\n",
            "Installing collected packages: quantile-python, ninja, websockets, uvloop, ujson, python-dotenv, pynvml, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, httptools, h11, dill, cupy-cuda12x, colorlog, backoff, watchfiles, uvicorn, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, httpcore, alembic, aioprometheus, optuna, nvidia-cusolver-cu12, httpx, fastapi, transformers, torch, ray, openai, datasets, xformers, dspy-ai, vllm\n",
            "  Attempting uninstall: cupy-cuda12x\n",
            "    Found existing installation: cupy-cuda12x 12.2.0\n",
            "    Uninstalling cupy-cuda12x-12.2.0:\n",
            "      Successfully uninstalled cupy-cuda12x-12.2.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.37.2\n",
            "    Uninstalling transformers-4.37.2:\n",
            "      Successfully uninstalled transformers-4.37.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.2 aioprometheus-23.12.0 alembic-1.13.1 backoff-2.2.1 colorlog-6.8.2 cupy-cuda12x-12.1.0 datasets-2.14.7 dill-0.3.7 dspy-ai-2.3.1 fastapi-0.110.0 h11-0.14.0 httpcore-1.0.4 httptools-0.6.1 httpx-0.27.0 multiprocess-0.70.15 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 openai-1.12.0 optuna-3.5.0 orjson-3.9.15 pynvml-11.5.0 python-dotenv-1.0.1 quantile-python-1.1 ray-2.9.3 starlette-0.36.3 torch-2.1.2 transformers-4.38.1 ujson-5.9.0 uvicorn-0.27.1 uvloop-0.19.0 vllm-0.3.2 watchfiles-0.21.0 websockets-12.0 xformers-0.0.23.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install dspy-ai vllm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run server in foreground\n",
        "# !python -m vllm.entrypoints.openai.api_server --model TheBloke/dolphin-2.6-mistral-7B-dpo-laser-AWQ --quantization awq\n",
        "\n",
        "# Run server in the background\n",
        "!nohup python -m vllm.entrypoints.openai.api_server --model TheBloke/dolphin-2.6-mistral-7B-dpo-laser-AWQ --quantization awq > server.log 2>&1 &\n",
        "# stdout is redirected to a file `server.log` using `> server.log`.\n",
        "# We use a quantized model prepared using AWQ quantization"
      ],
      "metadata": {
        "id": "07Jt1JJ4yM1a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell again and again to monitor the status of the server.\n",
        "# The server can take a few mintues to start.\n",
        "# Once the server has started, you will see logs such as this:\n",
        "# INFO 02-10 07:16:43 llm_engine.py:877] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
        "!tail server.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdJYF7w33hR7",
        "outputId": "499ca339-603c-427c-a840-efb353edfa52"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO 02-26 12:17:29 metrics.py:161] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
            "INFO 02-26 12:17:39 metrics.py:161] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
            "INFO 02-26 12:17:49 metrics.py:161] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
            "INFO 02-26 12:17:59 metrics.py:161] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
            "INFO 02-26 12:18:09 metrics.py:161] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
            "INFO 02-26 12:18:19 metrics.py:161] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
            "INFO 02-26 12:18:29 metrics.py:161] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
            "INFO 02-26 12:18:39 metrics.py:161] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
            "INFO 02-26 12:18:49 metrics.py:161] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
            "INFO 02-26 12:18:59 metrics.py:161] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Once the server is up and running, this should work\n",
        "!curl http://localhost:8000/v1/models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXH6ULj6yZBF",
        "outputId": "b4a770c8-a5d1-4084-aa3f-159faf4fdff8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"object\":\"list\",\"data\":[{\"id\":\"TheBloke/dolphin-2.6-mistral-7B-dpo-laser-AWQ\",\"object\":\"model\",\"created\":1708949943,\"owned_by\":\"vllm\",\"root\":\"TheBloke/dolphin-2.6-mistral-7B-dpo-laser-AWQ\",\"parent\":null,\"permission\":[{\"id\":\"modelperm-da2e39ff6119457a829dd7b8a1c141d6\",\"object\":\"model_permission\",\"created\":1708949943,\"allow_create_engine\":false,\"allow_sampling\":true,\"allow_logprobs\":true,\"allow_search_indices\":false,\"allow_view\":true,\"allow_fine_tuning\":false,\"organization\":\"*\",\"group\":null,\"is_blocking\":false}]}]}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DSPy: 𝗗eclarative 𝗦elf-improving Language 𝗣rograms"
      ],
      "metadata": {
        "id": "CgHqg5za5CZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "from dspy.evaluate import Evaluate\n",
        "from dspy.teleprompt import BootstrapFewShot, BootstrapFewShotWithRandomSearch, BootstrapFinetune"
      ],
      "metadata": {
        "id": "-k-t4RSfv-Ur"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = dspy.HFClientVLLM(model=\"TheBloke/dolphin-2.6-mistral-7B-dpo-laser-AWQ\", port=8000, url=\"http://localhost\")\n",
        "\n",
        "dspy.settings.configure(lm=lm)"
      ],
      "metadata": {
        "id": "YwdocZAzwCnt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = dspy.Predict('question -> answer')\n",
        "\n",
        "predict(question=\"What is the capital of Germany?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxd3VncpwSa3",
        "outputId": "93daa866-77b5-4acd-ea37-15acd215f772"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Prediction(\n",
              "    answer='Berlin'\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DSPY.SIGNATURES**"
      ],
      "metadata": {
        "id": "mTA66FtKTFCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GMCPQ(dspy.Signature):\n",
        "  \"\"\" How would you rate the doctor at the following criteria, on a 5 point scale. Poor Less than Satisfactory Satisfactory Good Very Good Cannot rate / Does not apply\"\"\"\n",
        "\n",
        "conversation= dspy.InputField(desc=\"conversation between doctor and patient\")\n",
        "#context= dspy.InputField(desc=\"Criteria: Being polite\")\n",
        "ratings= dspy.OutputField(desc=\"\"\"ratings of doctor on criteria: being polite\"\"\")\n"
      ],
      "metadata": {
        "id": "ntssH5efTEVu"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Being polite;\n",
        "Making you feel at ease;\n",
        " Listening to you;\n",
        "Assessing your medical condition;\n",
        "Explaining your condition and treatment;\n",
        "Involving you in decisions about your treatment;\n",
        "Providing or arranging treatment for you"
      ],
      "metadata": {
        "id": "G0kMphdsYB3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convo=\"\"\"Patient – Good afternoon, Doctor.\n",
        "\n",
        "Doctor – Good afternoon, Mr. Bose. How are you?\n",
        "\n",
        "Patient – I’m doing good, doctor, but my daughter isn’t doing well. Everywhere, people are getting affected with COVID and I am really worried about her.\n",
        "\n",
        "Doctor – Please have a seat and tell me what happened.\n",
        "\n",
        "Patient – Last week, my daughter came back from Pune as her college was closed on account of COVID. From the second day, she has had high fever and has been coughing badly. I think that she has contracted the virus on her way home.\n",
        "\n",
        "Doctor – Okay, I understand your concern. Having a fever and cough doesn’t necessarily mean that someone has contracted the virus. These are symptoms of common cold too. The change in the temperature of the atmosphere could have triggered these symptoms. Still, to put your worries to rest, I am prescribing some medicines and an RT PCR test. Do the test by tomorrow, and if the test results are positive, make sure she is isolated. On the other hand, if the result is negative, just give her the medicine and ask her to drink a lot of water. Also, bring her in so I could examine her.\n",
        "\n",
        "Patient – Okay, doctor. I will bring her in the evening. Thank you.\n",
        "\n",
        "Doctor – You are welcome.\"\"\""
      ],
      "metadata": {
        "id": "NXEiiw2SW9cu"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "judge = dspy.ChainOfThought(signature=GMCPQ, )\n",
        "judge(conversation=convo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "47xjZmliZvbJ",
        "outputId": "7e69f6a1-e37f-40e1-e4c3-42d00dcaf18f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected at least 1, got 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-85f9acb8b0da>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjudge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChainOfThought\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGMCPQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mjudge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/predict/chain_of_thought.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, signature, rationale_type, activated, **config)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;34m*\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_fields\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         rationale_type = rationale_type or dspy.OutputField(\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected at least 1, got 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class search_retrieval(dspy.Signature):\n",
        "  \"\"\"What are the specific patient demographics/symptoms/management plan for the condition\"\"\"\n",
        "\n",
        "condition = dspy.InputField(desc=“medical condition”)\n",
        "passage=dspy.OutputField(desc=”a passage including specific patient demographics/symptoms/management plan”)\n"
      ],
      "metadata": {
        "id": "P8JDli3VeysD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Search Retrieval"
      ],
      "metadata": {
        "id": "DWlVl4SvfZJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`What are the specific patient demographics/symptoms/management plan for the condition [Condition]?`"
      ],
      "metadata": {
        "id": "dilW49zXhywe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"What are the specific patient demographics/symptoms/management plan for the condition?\"\"\"\n",
        "#INPUT\n",
        "condition = dspy.InputField(desc=\"medical condition\")\n",
        "\n",
        "#OUTPUT\n",
        "passage=dspy.OutputField(desc=\"a passage including specific patient demographics/symptoms/management plan\")"
      ],
      "metadata": {
        "id": "LSvZHZSVfam9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Passage Filtering Template"
      ],
      "metadata": {
        "id": "2HVmu5y7f2XF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "For the clinical condition, [Condition], is the following a good description of common demographics/symptoms/management plans (Yes/No)?\n",
        "Description: [Retrieved Passage]\n",
        "Answer (Yes/No):\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "DPSyrrHQhtu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"For the clinical condition, is the following a good description of common demographics/symptoms/management plans (Yes/No)?\"\"\"\n",
        "#INPUT\n",
        "condition = dspy.InputField(desc=\"medical condition\")\n",
        "passage=dspy.InputField(desc=\"a passage including specific patient demographics/symptoms/management plan\")\n",
        "\n",
        "#OUTPUT\n",
        "is_good = dspy.OutputField(desc=\"Yes/No\")"
      ],
      "metadata": {
        "id": "ON8q7ywLf1xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vignette Generation Template\n"
      ],
      "metadata": {
        "id": "zU7VHisNiCU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "The following are several passages about the demographics, symptoms, and management plan for a given condition. Generate 2 different patient vignettes consistent with these passages. Follow the format of the given example (just list N/A if a particular field is unavailable).\n",
        "Condition: [Condition]\n",
        "Demographic Passages: [Retrieved Demographic Passages]\n",
        "Symptoms Passages: [Retrieved Symptom Passages]\n",
        "Management Plan Passages: [Retrieved Management Plan Passages]\n",
        "Example Format: [Oneshot example]\n",
        "Patient Vignettes for [Condition]:\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "i3u4KGUZiKIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"The following are several passages about the demographics, symptoms, and management plan for a given condition. Generate 2 different patient vignettes consistent with these passages. Follow the format of the given example (just list N/A if a particular field is unavailable)\"\"\"\n",
        "#INPUT\n",
        "condition = dspy.InputField(desc=\"medical condition\")\n",
        "\n",
        "demographic_passages= dspy.InputField(desc=\"[Retrieved Demographic Passages]\")\n",
        "\n",
        "symptom_passages= dspy.InputField(desc=\"[Retrieved Symptom Passages]\")\n",
        "\n",
        "management_passages= dspy.InputField(desc=\"[Retrieved Management Passages]\")\n",
        "\n",
        "example = dspy.InputField(desc=\"[Oneshot example]\")\n",
        "\n",
        "#OUTPUT\n",
        "vignette=dspy.OutputField(desc=\"2 different patient Vignettes for [MedicalCondition]:)\")\n"
      ],
      "metadata": {
        "id": "VEWDE5w_ifSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Patient Agent"
      ],
      "metadata": {
        "id": "PwZbSnjfmmCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "You are a patient chatting with a doctor over an online chat interface. The doctor has never met you before. <patient vignette> Respond to the doctor's questions honestly as they interview you, asking any questions that may come up.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "NjOwxO6gmoQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"You are a patient chatting with a doctor over an online chat interface. The doctor has never met you before. <patient vignette> Respond to the doctor's questions honestly as they interview you, asking any questions that may come up.\"\"\"\n",
        "\n",
        "#INPUT\n",
        "vignette=dspy.InputField(desc=\"patient vignette\")\n",
        "\n",
        "doctors_question=dspy.InputField(desc=\"doctor's question\")\n",
        "\n",
        "#OUTPUT\n",
        "patients_response=dspy.OutputField(desc=\"Response to the doctor's questions, along with any questions that may come up.\")\n",
        "\n",
        "\n",
        "#ALTERNATIVE OUTPUT\n",
        "patients_response=dspy.OutputField(desc=\"Response to the doctor's questions.\")\n",
        "patients_question=dspy.OutputField(desc=\"Any questions that may come up.\")"
      ],
      "metadata": {
        "id": "JWoRuxZkmh-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Doctor Agent"
      ],
      "metadata": {
        "id": "Rq7BXR3Tr-T_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`You are an empathetic clinician asking a patient about their medical history over an online chat interface. You know nothing about the patient in advance. Respond to the patient with a single-turn response to better understand their history and symptoms. Do not ask more than two questions. If the patient asks a question, be sure to answer it appropriately.`"
      ],
      "metadata": {
        "id": "2rU1d5ZesBuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"You are an empathetic clinician asking a patient about their medical history over an online chat interface. You know nothing about the patient in advance. Respond to the patient with a single-turn response to better understand their history and symptoms. Do not ask more than two questions. If the patient asks a question, be sure to answer it appropriately.\"\"\"\n",
        "\n",
        "#INPUT\n",
        "patients_response=dspy.InputField(desc=\"patient's response\")\n",
        "\n",
        "#OUTPUT\n",
        "doctors_response=dspy.OutputField(desc=\"Response to the patient's questions, along with any questions that may come up.\")\n",
        "\n",
        "\n",
        "#ALTERNATIVE OUTPUT\n",
        "response=dspy.OutputField(desc=\"Response to the patient's questions.\")\n",
        "doctors_question=dspy.OutputField(desc=\"Any questions that may come up. Do not ask more than 2 questions.\")\n",
        "\n",
        "\n",
        "#ASSERT SUGGEST\n",
        "\"\"\"Respond to the patient with a single-turn response to better understand their history and symptoms.\n",
        "Do not ask more than two questions.\"\"\""
      ],
      "metadata": {
        "id": "V449Aav7q_RP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self Play Critic"
      ],
      "metadata": {
        "id": "lTPDZNO0wp3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Act as a critic aware of the ground truth diagnosis, to provide in-context feedback to the doctor agent for selfimprovement which can enhance its performance\"\"\"\n",
        "#INPUT\n",
        "\n",
        "ground_truth=dspy.InputField(desc=\"ground truth\")\n",
        "preeceding_conversation=dspy.InputField(desc=\"preeceding conversation\")\n",
        "doctors_response=dspy.InputField(desc=\"doctor's response\")\n",
        "\n",
        "#OUTPUT\n",
        "empathy = dspy.OutputField(desc=\"\"\"Rating(0 to 5) of the doctor's response based on if the doctor agent exhibits empathy and professionalism while addressing the patient’s latest questions or comments in a concise manner.\n",
        "0: Complete lack of empathy and professionalism, responses are dismissive or unhelpful.\n",
        "1: Minimal empathy and professionalism, responses are brief and lack warmth or understanding.\n",
        "2: Some empathy and professionalism, responses are moderately concise but lack depth or personalization.\n",
        "3: Good empathy and professionalism, responses are sufficiently concise and demonstrate understanding.\n",
        "4: High level of empathy and professionalism, responses are very concise yet convey genuine concern and understanding.\n",
        "5: Excellent empathy and professionalism, responses are exceptionally concise, demonstrating deep empathy and professionalism.\"\"\")\n",
        "\n",
        "\n",
        "repititve_questions=dspy.OutputField(desc=\"\"\"The doctor agent avoids asking too many or repetitive questions (about information already acquired), focusing on a maximum of one or two questions per response.(Yes/No)\"\"\")\n",
        "\n"
      ],
      "metadata": {
        "id": "C2MzBrxct1VF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}